{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "import jax.numpy as jnp\n",
    "from PIL.ImageChops import offset\n",
    "from jax import grad, jit, vmap\n",
    "from jax import random\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "from qtconsole.mainwindow import background\n",
    "from scipy.stats import alpha\n",
    "\n",
    "from Utils.models import *\n",
    "from Utils.simulation import *\n",
    "from Utils.plot_utils import *\n",
    "\n",
    "import time\n",
    "from copy import copy\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "2**7",
   "id": "5aaae10ced18fa3f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "params_dict = {\n",
    "    \"dataset_parameters\": {\n",
    "        \"n_samples\": 200 \n",
    "    },\n",
    "    \"network_parameters\": {\n",
    "        \"input_size\": 64,\n",
    "        \"hidden_size\": 128,\n",
    "        \"output_size\": 1,\n",
    "        \"bias\": 1,\n",
    "    },\n",
    "    \"training_parameters\": {\n",
    "        \"num_epochs\": 100,\n",
    "        \"learning_rate\": 0.01\n",
    "    },\n",
    "    \"simulation_parameters\": {\n",
    "        \"mu\": 1,\n",
    "        \"sigma\": 0.1,\n",
    "        \"theta\": 0.02,\n",
    "        \"dt\": 0.001,\n",
    "        \"tau\": 0.005\n",
    "    },\n",
    "    \"seed\": 42\n",
    "}"
   ],
   "id": "29b5f793ba385b05",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "rng = random.key(params_dict[\"seed\"])",
   "id": "6eb909df34109dc0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "mu_LN = mu_LN_from_params(**params_dict[\"simulation_parameters\"])\n",
    "sigma_LN = sigma_LN_from_params(**params_dict[\"simulation_parameters\"])\n",
    "\n",
    "rng, net_key = random.split(rng)\n",
    "params = init_elm(net_key, mu_LN, sigma_LN, **params_dict[\"network_parameters\"])"
   ],
   "id": "92d5b3928c37d345",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#histogram of the weights of W_i\n",
    "plt.hist(params['W_i'].flatten(), bins=100)\n",
    "plt.show()\n"
   ],
   "id": "4c4ebfe696401376",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# simulate perturbations of the weights of W_i\n",
    "simulation_parameters = params_dict[\"simulation_parameters\"]\n",
    "rng, sim_key = random.split(rng)\n",
    "weight_list = simulate_perturbation_only(sim_key, params['W_i'].flatten(), 1000, simulation_parameters['mu'], simulation_parameters['theta'], simulation_parameters['sigma'], simulation_parameters['dt'])\n"
   ],
   "id": "857a7b04db549de5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "plt.plot(weight_list[:, :100])",
   "id": "366d844718cd1dee",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#histogram of final weights\n",
    "plt.hist(weight_list[-1], bins=100, color='r')\n",
    "plt.hist(params['W_i'].flatten(), bins=100)\n",
    "plt.show()\n",
    "\n"
   ],
   "id": "2b232183ed57b180",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#simulate perturbations of the weights of W_i\n",
    "rng, sim_key = random.split(rng)\n",
    "W_f = time_evolution_GOU(sim_key, params['W_i'], **simulation_parameters)\n",
    "\n"
   ],
   "id": "e6893e33106683fe",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "plt.hist(weight_list[-1], bins=100, color='r')\n",
    "plt.hist(W_f.flatten(), bins=100)\n",
    "plt.show()"
   ],
   "id": "e9d25b45b90c9665",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "rng, data_key = random.split(rng)\n",
    "\n",
    "X_train, y_train = create_binary_dataset(data_key, \n",
    "                                         n_samples=params_dict[\"dataset_parameters\"][\"n_samples\"],\n",
    "                                         input_dim=params_dict[\"network_parameters\"][\"input_size\"])"
   ],
   "id": "81b4d23d24d221f2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "loss_list = []\n",
    "acc_list = []\n",
    "\n",
    "training_parameters = params_dict[\"training_parameters\"]\n",
    "num_epochs = training_parameters[\"num_epochs\"]\n",
    "learning_rate = training_parameters[\"learning_rate\"]\n",
    "simulation_parameters = params_dict[\"simulation_parameters\"]\n",
    "\n",
    "weight_list = []\n",
    "rng = random.key(params_dict[\"seed\"])\n",
    "for epoch in range(num_epochs):\n",
    "    start_time = time.time()\n",
    "    for x,y in zip(X_train,y_train):\n",
    "\n",
    "        rng, gou_key = random.split(rng)\n",
    "        #perturb the weights of W_i\n",
    "        params['W_i'] = time_evolution_GOU(gou_key, params['W_i'], **simulation_parameters)\n",
    "        #params['W_i'] += perturb_GOU(gou_key, params['W_i'], simulation_parameters['mu'], simulation_parameters['theta'], simulation_parameters['sigma'], simulation_parameters['dt'])\n",
    "        \n",
    "        grads = grad(loss_elm)(params, x, y)\n",
    "        params['W_i'] -= learning_rate * grads['W_i']\n",
    "        params['W_o'] -= learning_rate * grads['W_o']\n",
    "        params['b_i'] -= learning_rate * grads['b_i']\n",
    "        params['b_o'] -= learning_rate * grads['b_o']\n",
    "            \n",
    "        weight_list.append(params['W_i'].flatten())\n",
    "        \n",
    "    acc_list.append(accuracy_elm(params, X_train, y_train))\n",
    "    loss_list.append(loss_elm(params, X_train, y_train))\n",
    "\n",
    "\n",
    "    if epoch%10==0:\n",
    "        epoch_time = time.time() - start_time\n",
    "        train_loss = loss_elm(params, X_train, y_train)\n",
    "        train_acc = accuracy_elm(params, X_train, y_train)\n",
    "        print(\"Epoch {} in {:0.2f} sec\".format(epoch, epoch_time))\n",
    "        print(\"Training set loss {}\".format(train_loss))\n",
    "        print(\"Training set accuracy {}\".format(train_acc))\n",
    "\n",
    "\n"
   ],
   "id": "8f3d3a832e0dddd8",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "weight_list = np.array(weight_list)\n",
    "plt.hist(weight_list[-1], bins=500)\n",
    "plt.show()\n"
   ],
   "id": "6cba6769471ae7dd",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#make a long figure\n",
    "plt.figure(figsize=(20,5))\n",
    "\n",
    "#plot \n",
    "\n",
    "# put a  vertical line every 200 steps\n",
    "for i in range(0, num_epochs*200, 200):\n",
    "    plt.axvline(x=i, color='r', linestyle='--', alpha = 0.1)\n",
    "plt.plot(weight_list[:, :100], alpha=0.5, c = 'b')\n",
    "\n",
    "plt.show()\n",
    "    \n",
    "\n"
   ],
   "id": "43ebbee0d0d9656d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#save the data\n",
    "np.save(\"old_results/weight_list_training.npy\", weight_list)"
   ],
   "id": "aedd75c4399d808",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "weight_list = np.load(\"old_results/weight_list_training.npy\")\n",
    "\n",
    "fig, axs = plt.subplots(1, 3, figsize=(15, 3), gridspec_kw={'width_ratios': [1, 4, 1]})\n",
    "\n",
    "# Plot the initial weights\n",
    "axs[0].hist(weight_list[0], bins=500)\n",
    "axs[0].set_title(\"Initial weights\")\n",
    "axs[0].set_xlim(0, 5)\n",
    "# Plot the weight evolution\n",
    "\n",
    "for i in np.arange(0, num_epochs, 1):\n",
    "    axs[1].axvline(x=i*(simulation_parameters['tau'])*200, alpha = 0.1)\n",
    "times = np.arange(0, num_epochs*200) * simulation_parameters['tau']\n",
    "axs[1].plot(times, weight_list[:, :20], alpha=0.5, c = 'b')\n",
    "axs[1].set_title(\"Weight evolution\")\n",
    "axs[1].set_xlim(0, num_epochs*200*simulation_parameters['tau'])\n",
    "\n",
    "# Plot the final weights\n",
    "axs[2].hist(weight_list[-1], bins=500)\n",
    "axs[2].set_title(\"Final weights\")\n",
    "axs[2].set_xlim(0, 5)\n",
    "\n",
    "plt.savefig(\"weight_evolution.png\", dpi=300, bbox_inches='tight')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "id": "7a978e09ac8007db",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "times.shape",
   "id": "bc28f178b3764899",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#plot losses and accuracy next to each other\n",
    "fig, ax = plt.subplots(1,2, figsize=(10,5))\n",
    "ax[0].plot(loss_list)\n",
    "ax[0].set_title(\"Loss\")\n",
    "ax[1].plot(acc_list)\n",
    "ax[1].set_title(\"Accuracy\")\n",
    "plt.show()\n"
   ],
   "id": "20166b39373ed47f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "    #plot losses and accuracy next to each other\n",
    "fig, ax = plt.subplots(1,2, figsize=(10,5))\n",
    "ax[0].plot(loss_list)\n",
    "ax[0].set_title(\"Loss\")\n",
    "ax[1].plot(acc_list)\n",
    "ax[1].set_title(\"Accuracy\")\n",
    "plt.show()\n",
    "\n"
   ],
   "id": "b4515d348284dea4",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "for epoch in range(num_epochs):\n",
    "    start_time = time.time()\n",
    "    for x,y in zip(X_train,y_train):\n",
    "        #perturb the weights of W_i\n",
    "        rng, gou_key = random.split(rng)\n",
    "        params['W_i'] = time_evolution_GOU(gou_key, params['W_i'], **simulation_parameters)\n",
    "\n",
    "    acc_list.append(accuracy_elm(params, X_train, y_train))\n",
    "    loss_list.append(loss_elm(params, X_train, y_train))\n",
    "\n",
    "\n",
    "    if epoch%10==0:\n",
    "        epoch_time = time.time() - start_time\n",
    "        train_loss = loss_elm(params, X_train, y_train)\n",
    "        train_acc = accuracy_elm(params, X_train, y_train)\n",
    "        print(\"Epoch {} in {:0.2f} sec\".format(epoch, epoch_time))\n",
    "        print(\"Training set loss {}\".format(train_loss))\n",
    "        print(\"Training set accuracy {}\".format(train_acc))"
   ],
   "id": "93bd713af820ac8b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#plot losses and accuracy next to each other\n",
    "fig, ax = plt.subplots(1,2, figsize=(10,5))\n",
    "ax[0].plot(loss_list)\n",
    "ax[0].set_title(\"Loss\")\n",
    "ax[1].plot(acc_list)\n",
    "ax[1].set_title(\"Accuracy\")\n",
    "#vertical line to show the end of the training\n",
    "ax[0].axvline(x=num_epochs, color='r', linestyle='--')\n",
    "ax[1].axvline(x=num_epochs, color='r', linestyle='--')\n",
    "plt.show()\n"
   ],
   "id": "91d2c52131b8461f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "plt.figure(figsize=(3,3))\n",
    "epochs_time = np.arange(0, num_epochs*2)*simulation_parameters['tau']*200\n",
    "plt.plot(epochs_time,acc_list, 'r', label='Accuracy')\n",
    "#vertical line to show the end of the training\n",
    "plt.axvline(x=num_epochs*200*simulation_parameters['tau'], color='k', alpha = 0.5)\n",
    "# write that the vertical line is the end of training\n",
    "plt.text(num_epochs*187*simulation_parameters['tau'],  0.52,'End of training',rotation=90)\n",
    "#horizonatal line at 0.5\n",
    "plt.axhline(y=0.5, color='g', linestyle='--')\n",
    "#transparent legend\n",
    "plt.legend(fontsize=9)\n",
    "plt.xlim(50,130)\n",
    "plt.savefig(\"accuracy.png\", dpi=300, bbox_inches='tight')\n",
    "\n",
    "plt.plot()"
   ],
   "id": "4b9186ec578e1e86",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "803a9106b31eb57c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# DIFFERENT TAUS",
   "id": "2ea65d57fde265bf"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "rng = random.key(params_dict[\"seed\"])\n",
    "\n",
    "mu_LN = mu_LN_from_params(**params_dict[\"simulation_parameters\"])\n",
    "sigma_LN = sigma_LN_from_params(**params_dict[\"simulation_parameters\"])\n",
    "\n",
    "rng, data_key = random.split(rng)\n",
    "\n",
    "X_train, y_train = create_binary_dataset(data_key, n_samples=params_dict[\"dataset_parameters\"][\"n_samples\"], input_dim=params_dict[\"network_parameters\"][\"input_size\"])\n",
    "\n",
    "tau_list = jnp.arange(0.00, 0.05, 0.005)\n",
    "loss_tau = []\n",
    "acc_tau = []\n",
    "\n",
    "training_parameters = params_dict[\"training_parameters\"]\n",
    "num_epochs = training_parameters[\"num_epochs\"]\n",
    "learning_rate = training_parameters[\"learning_rate\"]\n",
    "simulation_parameters = params_dict[\"simulation_parameters\"]\n",
    "\n",
    "print('tau_list', tau_list)\n",
    "\n",
    "for tau in tau_list:\n",
    "    print(\"Tau: \", tau)\n",
    "    simulation_parameters[\"tau\"] = tau\n",
    "    rng, net_key = random.split(rng)\n",
    "    params = init_elm(net_key, mu_LN, sigma_LN, **params_dict[\"network_parameters\"])\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        for x,y in zip(X_train,y_train):\n",
    "\n",
    "            rng, gou_key = random.split(rng)\n",
    "            #perturb the weights of W_i\n",
    "            \n",
    "            if tau != 0:\n",
    "                params['W_i'] = time_evolution_GOU(gou_key, params['W_i'], **simulation_parameters)\n",
    "            #params['W_i'] += perturb_GOU(gou_key, params['W_i'], simulation_parameters['mu'], simulation_parameters['theta'], simulation_parameters['sigma'], simulation_parameters['dt'])\n",
    "            \n",
    "            grads = grad(loss_elm)(params, x, y)\n",
    "            params['W_i'] -= learning_rate * grads['W_i']\n",
    "            params['W_o'] -= learning_rate * grads['W_o']\n",
    "            params['b_i'] -= learning_rate * grads['b_i']\n",
    "            params['b_o'] -= learning_rate * grads['b_o']\n",
    "            \n",
    "        if epoch%10==0:\n",
    "            print(\"Epoch {}. Acc = {}\".format(epoch,accuracy_elm(params, X_train, y_train)))          \n",
    "\n",
    "    print(\"Loss: \",loss_elm(params, X_train, y_train))\n",
    "    print(\"Accuracy: \", accuracy_elm(params, X_train, y_train))\n",
    "    acc_tau.append(accuracy_elm(params, X_train, y_train))\n",
    "    loss_tau.append(loss_elm(params, X_train, y_train))\n",
    "    "
   ],
   "id": "d70de136fe52c874",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#plot losses and accuracy next to each other\n",
    "fig, ax = plt.subplots(1,2, figsize=(10,5))\n",
    "ax[0].plot(tau_list, loss_tau, '.')\n",
    "ax[0].set_title(\"Loss\")\n",
    "ax[1].plot(tau_list,acc_tau, '.')\n",
    "ax[1].set_title(\"Accuracy\")\n",
    "plt.show()\n"
   ],
   "id": "163796c2672c3c76",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#save loss and accuracy\n",
    "np.save(\"old_results/loss_tau.npy\", loss_tau)\n",
    "np.save(\"old_results/acc_tau.npy\", acc_tau)\n"
   ],
   "id": "e7a2f063919bd8e3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "tau_list = jnp.arange(0.00, 0.05, 0.005)\n",
    "acc_tau = np.load(\"old_results/acc_tau_tot.npy\")\n",
    "\n",
    "plt.figure(figsize=(2,2))\n",
    "plt.plot(tau_list, np.mean(acc_tau, axis=1), 'r', label='Accuracy')\n",
    "plt.fill_between(tau_list, np.mean(acc_tau, axis=1) - np.std(acc_tau, axis=1),\n",
    "                   np.mean(acc_tau, axis=1) + np.std(acc_tau, axis=1), alpha=0.3, color = 'r')\n",
    "\n",
    "plt.xlabel('Tau')\n",
    "plt.ylim(0.4,1)\n",
    "#horizonatal line at 0.5\n",
    "plt.axhline(y=0.5, color='g', linestyle='--')\n",
    "plt.legend()\n",
    "plt.savefig(\"tau_accuracy.png\", dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ],
   "id": "7fa2008b5fe070cc",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "ax[0].plot(tau_list, np.mean(acc_tau, axis=1), label='Accuracy')\n",
    "ax[0].fill_between(tau_list, np.mean(acc_tau, axis=1) - np.std(acc_tau, axis=1),\n",
    "                   np.mean(acc_tau, axis=1) + np.std(acc_tau, axis=1), alpha=0.3)\n",
    "ax[0].set_xlabel('Tau')\n",
    "ax[0].set_ylabel('Accuracy')"
   ],
   "id": "1edee3b23561fd9e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# TAU EXPLORATION with MLP",
   "id": "b0e904da32e419a0"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "tau_list = jnp.arange(0.00, 0.1, 0.005)\n",
    "loss_tau = []\n",
    "acc_tau = []\n",
    "\n",
    "training_parameters = params_dict[\"training_parameters\"]\n",
    "num_epochs = training_parameters[\"num_epochs\"]\n",
    "learning_rate = training_parameters[\"learning_rate\"]\n",
    "simulation_parameters = params_dict[\"simulation_parameters\"]\n",
    "\n",
    "print('tau_list', tau_list)\n",
    "\n"
   ],
   "id": "b90b151897e6086a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "rng = random.key(params_dict[\"seed\"])\n",
    "\n",
    "mu_LN = mu_LN_from_params(**params_dict[\"simulation_parameters\"])\n",
    "sigma_LN = sigma_LN_from_params(**params_dict[\"simulation_parameters\"])\n",
    "\n",
    "tau_list = jnp.arange(0.00, 0.1, 0.005)\n",
    "loss_tau = []\n",
    "acc_tau = []\n",
    "\n",
    "training_parameters = params_dict[\"training_parameters\"]\n",
    "num_epochs = training_parameters[\"num_epochs\"]\n",
    "learning_rate = training_parameters[\"learning_rate\"]\n",
    "simulation_parameters = params_dict[\"simulation_parameters\"]\n",
    "\n",
    "print('tau_list', tau_list)\n",
    "\n",
    "for tau in tau_list:\n",
    "    print(\"Tau: \", tau)\n",
    "    simulation_parameters[\"tau\"] = tau\n",
    "    rng, net_key = random.split(rng)\n",
    "    params = init_mlp(net_key, mu_LN, sigma_LN, **params_dict[\"network_parameters\"])\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        start_time = time.time()\n",
    "        for x,y in zip(X_train,y_train):\n",
    "\n",
    "            rng, gou_key = random.split(rng)\n",
    "            #perturb the weights of W_i\n",
    "            \n",
    "            if tau != 0:\n",
    "                params['W_h'] = time_evolution_GOU(gou_key, params['W_h'], **simulation_parameters)\n",
    "            #params['W_i'] += perturb_GOU(gou_key, params['W_i'], simulation_parameters['mu'], simulation_parameters['theta'], simulation_parameters['sigma'], simulation_parameters['dt'])\n",
    "            \n",
    "            grads = grad(loss_mlp)(params, x, y)\n",
    "            params['W_i'] -= learning_rate * grads['W_i']\n",
    "            params['W_h'] -= learning_rate * grads['W_h']\n",
    "            params['W_o'] -= learning_rate * grads['W_o']\n",
    "                \n",
    "        if epoch%10==0:\n",
    "            epoch_time = time.time() - start_time\n",
    "            print(\"Epoch {} in {:0.2f} sec. Acc = {}\".format(epoch, epoch_time,accuracy_mlp(params, X_train, y_train)))              \n",
    "\n",
    "    print(\"Loss: \",loss_mlp(params, X_train, y_train))\n",
    "    print(\"Accuracy: \", accuracy_mlp(params, X_train, y_train))\n",
    "    acc_tau.append(accuracy_mlp(params, X_train, y_train))\n",
    "    loss_tau.append(loss_mlp(params, X_train, y_train))\n",
    "\n"
   ],
   "id": "9d42790bd7309683",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "29c0f630b25b508d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "loss_list = []\n",
    "acc_list = []\n",
    "\n",
    "params = init_elm(net_key, mu_LN, sigma_LN, **params_dict[\"network_parameters\"])\n",
    "\n",
    "rng, data_key = random.split(rng)\n",
    "\n",
    "X_train, y_train = create_binary_dataset(data_key, \n",
    "                                         n_samples=params_dict[\"dataset_parameters\"][\"n_samples\"],\n",
    "                                         input_dim=params_dict[\"network_parameters\"][\"input_size\"])\n",
    "\n",
    "training_parameters = params_dict[\"training_parameters\"]\n",
    "num_epochs = training_parameters[\"num_epochs\"]\n",
    "learning_rate = training_parameters[\"learning_rate\"]\n",
    "simulation_parameters = params_dict[\"simulation_parameters\"]\n",
    "\n",
    "weight_list = []\n",
    "rng = random.key(params_dict[\"seed\"])\n",
    "for epoch in range(23):\n",
    "    start_time = time.time()\n",
    "    for x,y in zip(X_train,y_train):\n",
    "\n",
    "        rng, gou_key = random.split(rng)\n",
    "        #perturb the weights of W_i\n",
    "        n_steps = int(simulation_parameters['tau'] /simulation_parameters['dt'])\n",
    "\n",
    "        for _ in range(n_steps):\n",
    "            gou_key, sim_key = random.split(gou_key)\n",
    "            params['W_i'] += perturb_GOU(sim_key, \n",
    "                                         params['W_i'],  \n",
    "                                         simulation_parameters['mu'], \n",
    "                                         simulation_parameters['theta'],  \n",
    "                                         simulation_parameters['sigma'], \n",
    "                                         simulation_parameters['dt'])\n",
    "            if epoch >= 20:\n",
    "                weight_list.append(params['W_i'].flatten())\n",
    "        \n",
    "        grads = grad(loss_elm)(params, x, y)\n",
    "        params['W_i'] -= learning_rate * grads['W_i']\n",
    "        params['W_o'] -= learning_rate * grads['W_o']\n",
    "        params['b_i'] -= learning_rate * grads['b_i']\n",
    "        params['b_o'] -= learning_rate * grads['b_o']\n",
    "            \n",
    "        if epoch >= 20:\n",
    "                weight_list.append(params['W_i'].flatten())\n",
    "        \n",
    "    if epoch >= 20:\n",
    "                acc_list.append(accuracy_elm(params, X_train, y_train))\n",
    "                loss_list.append(loss_elm(params, X_train, y_train))\n",
    "\n",
    "\n",
    "    if epoch%10==0:\n",
    "        epoch_time = time.time() - start_time\n",
    "        train_loss = loss_elm(params, X_train, y_train)\n",
    "        train_acc = accuracy_elm(params, X_train, y_train)\n",
    "        print(\"Epoch {} in {:0.2f} sec\".format(epoch, epoch_time))\n",
    "        print(\"Training set loss {}\".format(train_loss))\n",
    "        print(\"Training set accuracy {}\".format(train_acc))\n",
    "\n"
   ],
   "id": "e44cde9d9088a694",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "weight_list = np.array(weight_list)\n",
    "\n",
    "weight_list.shape"
   ],
   "id": "10450e0af79dd3aa",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "fig = plt.figure(figsize=(5,2))\n",
    "off_set = 20\n",
    "n_steps = int(simulation_parameters['tau']  /simulation_parameters['dt'])\n",
    "\n",
    "for i in range(0, weight_list.shape[0] + 1, n_steps + 1):\n",
    "    plt.axvline(x=i*simulation_parameters['tau'] + off_set, color='g', linestyle='dotted', alpha = 0.1)\n",
    "\n",
    "#plot a vertical line every epoch\n",
    "for i in range(0, 100 , 1):\n",
    "    plt.axvline(x=i)\n",
    "\n",
    "times = np.arange(0, weight_list.shape[0]) * simulation_parameters['dt']\n",
    "plt.plot(times + off_set, weight_list[:, :20], alpha=0.5, c = 'b')\n",
    "plt.tight_layout()\n",
    "# plt.xlim(off_set, off_set+weight_list.shape[0]*simulation_parameters['dt'])\n",
    "plt.xlim(20, 22)\n",
    "plt.savefig(\"weight_evolution_zoom.png\", dpi=300, bbox_inches='tight')\n",
    "plt.show()\n"
   ],
   "id": "938fdb3406bfc01b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "weight_list.shape\n",
   "id": "bd8dd449fa6b1da6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "7600/2",
   "id": "265eb2a9b2556c96",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "3800/5",
   "id": "18a3f03c7dfb458f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "acc_list",
   "id": "9a43457848102408",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "5fda10a48ec2f120",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
